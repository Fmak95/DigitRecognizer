{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DigitRecognizer Challenge:\n",
    "This notebook will be a tutorial on how to use Neural Network frameworks like Tensorflow and Keras to recognize handwritten digit images that are provided on kaggle <a href = \"https://www.kaggle.com/c/digit-recognizer\">here.</a>\n",
    "\n",
    "The dataset is a csv file containing 784 features and 1 label. The available features are the grayscale values of each pixel of the image (0 - 255). Each image has a resolution of 28x28.\n",
    "\n",
    "1. [Data Load & Visualization](#DataLoad)\n",
    "2. [Data Preprocessing](#DataPreprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"DataLoad\">Data Load & Visualization</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.456643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219286</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.02019</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.887730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.312890</td>\n",
       "      <td>4.633819</td>\n",
       "      <td>3.274488</td>\n",
       "      <td>1.75987</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>0.414264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\n",
       "count  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
       "mean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel6   pixel7   pixel8  ...      pixel774      pixel775  \\\n",
       "count  42000.0  42000.0  42000.0  ...  42000.000000  42000.000000   \n",
       "mean       0.0      0.0      0.0  ...      0.219286      0.117095   \n",
       "std        0.0      0.0      0.0  ...      6.312890      4.633819   \n",
       "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "max        0.0      0.0      0.0  ...    254.000000    254.000000   \n",
       "\n",
       "           pixel776     pixel777      pixel778      pixel779  pixel780  \\\n",
       "count  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \n",
       "mean       0.059024      0.02019      0.017238      0.002857       0.0   \n",
       "std        3.274488      1.75987      1.894498      0.414264       0.0   \n",
       "min        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "25%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "50%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "75%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "max      253.000000    253.00000    254.000000     62.000000       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  \n",
       "count   42000.0   42000.0   42000.0  \n",
       "mean        0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0  \n",
       "25%         0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0  \n",
       "75%         0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Take a look at our data\n",
    "train = pd.read_csv(\"Data/train.csv\")\n",
    "test = pd.read_csv(\"Data/test.csv\")\n",
    "\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x123a6a198>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADTVJREFUeJzt3W+IXfWdx/HPx2z7JO0DTWM2WLPpFom7CLVlIguW4FIs2aWQhFCpombZ2umDihb3wY7mQQXJKItmdx8VJjQ0hdS2MJkY6rJtkbqjsIhxKNUmaSuSTdOExGChljwomu8+mDNlGuf+zp17z73nznzfLwj3z/eee78c8plz7v2dc36OCAHI55q2GwDQDsIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiCpvxjmh9nmcEJgwCLC3byury2/7e22f2n7TdsT/bwXgOFyr8f2214j6VeS7pR0VtKrku6OiBOFZdjyAwM2jC3/bZLejIi3IuKPkr4naUcf7wdgiPoJ/w2SfrPo8dnquT9je9z2cdvH+/gsAA3r5we/pXYtPrBbHxFTkqYkdvuBUdLPlv+spBsXPf64pHP9tQNgWPoJ/6uSbrL9CdsflvQlSceaaQvAoPW82x8R79l+UNKPJK2RdDAiftFYZwAGquehvp4+jO/8wMAN5SAfACsX4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJDXWKbmBUTE9PF+s7d+4s1ufm5or1rVu3LrunYWPLDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJ9TXOb/u0pHclvS/pvYgYa6IpoAk333xzx1rdOH7d7NWTk5M99TRKmjjI5+8j4lID7wNgiNjtB5LqN/wh6ce2X7M93kRDAIaj393+2yPinO3rJf3E9qmImF38guqPAn8YgBHT15Y/Is5VtxclzUi6bYnXTEXEGD8GAqOl5/DbXmv7owv3JX1e0htNNQZgsPrZ7d8gacb2wvt8NyL+u5GuAAxcz+GPiLckfarBXtJau3ZtsT4xMVGsHz58uGPt1KlTPfW0Guzevbtj7Zpryju9V65cKdZnZmZ66mmUMNQHJEX4gaQIP5AU4QeSIvxAUoQfSIpLd4+AuqG8Rx99tFjfvn17x9pKuIR0r9avX1+sP/DAAx1rdUN5R44c6amnlYQtP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kxTj/CKgbr66umdDRariMdC+eeOKJYn3Tpk0da3Wn9B49erSnnlYStvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBTj/ENQmipaknbt2lWs100XvRouIz0IpfV24sSJ4rIZ1ilbfiApwg8kRfiBpAg/kBThB5Ii/EBShB9Iqnac3/ZBSV+QdDEibqmeu07S9yVtlnRa0l0R8bvBtTna6qbYnp6eLtbrzuefnZ1ddk8ZbNu2rVgvXQfhzJkzxWUvX77cU08rSTdb/m9LunpWiAlJL0TETZJeqB4DWEFqwx8Rs5LeuerpHZIOVfcPSdrZcF8ABqzX7/wbIuK8JFW31zfXEoBhGPix/bbHJY0P+nMALE+vW/4LtjdKUnV7sdMLI2IqIsYiYqzHzwIwAL2G/5ikPdX9PZKea6YdAMNSG37bz0r6X0lbbJ+1/WVJT0m60/avJd1ZPQawgtR+54+IuzuUPtdwLyvWxER5pHPLli3F+ttvv12sP/LII8vuaTXYu3dvsV63Xkvn8+/bt6+nnlYTjvADkiL8QFKEH0iK8ANJEX4gKcIPJMWluxuwe/fuYr1uiu25ubm+6itV3anQ99xzT7Fet16npqY61l5++eXishmw5QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpBjn71Jpmu1+Ti2V8p5e2u+p0HXrFWVs+YGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcb5u1S6jHTdeeUvvfRSsb6Szy2vOye/dHxE3aW568bx69b7pUuXivXs2PIDSRF+ICnCDyRF+IGkCD+QFOEHkiL8QFK14/y2D0r6gqSLEXFL9dzjkr4iaWFu6cci4r8G1eQoKI1X141Hl5aVpP379xfrp06dKtYHadeuXcX6pk2bivXSOfl1662uPjk5Waw/+eSTxXp23Wz5vy1p+xLP/3tE3Fr9W9XBB1aj2vBHxKykd4bQC4Ah6uc7/4O2f277oO1rG+sIwFD0Gv5vSvqkpFslnZf0TKcX2h63fdz28R4/C8AA9BT+iLgQEe9HxBVJByTdVnjtVESMRcRYr00CaF5P4be9cdHDXZLeaKYdAMPSzVDfs5LukPQx22clfUPSHbZvlRSSTkv66gB7BDAAHua1z22v2Autl849f/jhh4vLrlu3rlivOy+9n/Pa+z0nfpDL1y173333FeuHDx8u1rOKiPKKrXCEH5AU4QeSIvxAUoQfSIrwA0kRfiAphvoacO+99xbrTz/9dLG+fv36Yn2QQ30HDhwo1uuMj48X66XPP3r0aHHZ+++/v1i/fPlysZ4VQ30Aigg/kBThB5Ii/EBShB9IivADSRF+ICnG+VG0bdu2Yv3FF18s1kv/v9asWdNLS6jBOD+AIsIPJEX4gaQIP5AU4QeSIvxAUoQfSKr2uv1Y3erG8Z95puNMbJLqrxdw5MiRZfeE4WDLDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJ1Z7Pb/tGSd+R9JeSrkiaioj/tH2dpO9L2izptKS7IuJ3Ne/F+fwj5sSJE8X6li1bivW5ublifevWrcvuCf1p8nz+9yT9S0T8jaS/k/Q1238raULSCxFxk6QXqscAVoja8EfE+YiYq+6/K+mkpBsk7ZB0qHrZIUk7B9UkgOYt6zu/7c2SPi3pFUkbIuK8NP8HQtL1TTcHYHC6Prbf9kckTUv6ekT8vjQ/3FXLjUsqT+gGYOi62vLb/pDmg384IhbO1Lhge2NV3yjp4lLLRsRURIxFxFgTDQNoRm34Pb+J/5akkxGxf1HpmKQ91f09kp5rvj0Ag9LNbv/tku6T9Lrtn1XPPSbpKUk/sP1lSWckfXEwLaIfe/fuLdbrhvLqhoInJyeX3RNGQ234I+JlSZ2+4H+u2XYADAtH+AFJEX4gKcIPJEX4gaQIP5AU4QeS4tLdq8DYWOeDJx966KHisnWHaU9NTRXrMzMzxTpGF1t+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iKcf5V4Pnnn+9YW7duXXHZ2dnZYv3AgQM99YTRx5YfSIrwA0kRfiApwg8kRfiBpAg/kBThB5KqnaK70Q9jim5g4JqcohvAKkT4gaQIP5AU4QeSIvxAUoQfSIrwA0nVht/2jbZ/avuk7V/Yfrh6/nHbv7X9s+rfPw6+XQBNqT3Ix/ZGSRsjYs72RyW9JmmnpLsk/SEinu76wzjIBxi4bg/yqb2ST0Scl3S+uv+u7ZOSbuivPQBtW9Z3ftubJX1a0ivVUw/a/rntg7av7bDMuO3jto/31SmARnV9bL/tj0j6H0n7IuKI7Q2SLkkKSU9o/qvBP9e8B7v9wIB1u9vfVfhtf0jSDyX9KCL2L1HfLOmHEXFLzfsQfmDAGjuxx/PTuH5L0snFwa9+CFywS9Iby20SQHu6+bX/s5JekvS6pCvV049JulvSrZrf7T8t6avVj4Ol92LLDwxYo7v9TSH8wOBxPj+AIsIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBStRfwbNglSf+36PHHqudG0aj2Nqp9SfTWqyZ7+6tuXzjU8/k/8OH28YgYa62BglHtbVT7kuitV231xm4/kBThB5JqO/xTLX9+yaj2Nqp9SfTWq1Z6a/U7P4D2tL3lB9CSVsJve7vtX9p+0/ZEGz10Yvu07dermYdbnWKsmgbtou03Fj13ne2f2P51dbvkNGkt9TYSMzcXZpZudd2N2ozXQ9/tt71G0q8k3SnprKRXJd0dESeG2kgHtk9LGouI1seEbW+T9AdJ31mYDcn2v0l6JyKeqv5wXhsR/zoivT2uZc7cPKDeOs0s/U9qcd01OeN1E9rY8t8m6c2IeCsi/ijpe5J2tNDHyIuIWUnvXPX0DkmHqvuHNP+fZ+g69DYSIuJ8RMxV99+VtDCzdKvrrtBXK9oI/w2SfrPo8VmN1pTfIenHtl+zPd52M0vYsDAzUnV7fcv9XK125uZhumpm6ZFZd73MeN20NsK/1GwiozTkcHtEfEbSP0j6WrV7i+58U9InNT+N23lJz7TZTDWz9LSkr0fE79vsZbEl+mplvbUR/rOSblz0+OOSzrXQx5Ii4lx1e1HSjOa/poySCwuTpFa3F1vu508i4kJEvB8RVyQdUIvrrppZelrS4Yg4Uj3d+rpbqq+21lsb4X9V0k22P2H7w5K+JOlYC318gO211Q8xsr1W0uc1erMPH5O0p7q/R9JzLfbyZ0Zl5uZOM0ur5XU3ajNet3KQTzWU8R+S1kg6GBH7ht7EEmz/tea39tL8GY/fbbM3289KukPzZ31dkPQNSUcl/UDSJklnJH0xIob+w1uH3u7QMmduHlBvnWaWfkUtrrsmZ7xupB+O8ANy4gg/ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJ/T8z2AAE6rMHLgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#store the data into lables and features\n",
    "train_y = train['label']\n",
    "train_x = train.drop(['label'], axis=1)\n",
    "\n",
    "#convert the data into a 28x28 matrix and view as an image:\n",
    "img1 = train_x.iloc[450] #random image, just to see how they look\n",
    "img1.values.reshape(28,28)\n",
    "plt.imshow(img1.values.reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"DataPreprocessing\">Data Preprocessing</a>\n",
    "\n",
    "So for this problem, I will be using a simple convolutional neural network. In order to do that, first I have to preprocess my data such that it resembles an image (Numpy Array with shape (28,28,1)). The following preprocess techniques will be used:\n",
    "- Perform one hot encoding on our labels (ex 3 = [0, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n",
    "- Reshape our input data into (28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(labels):\n",
    "    labels_encoded = []\n",
    "    for num in labels:\n",
    "        if num == 0:\n",
    "            labels_encoded.append([1, 0, 0, 0, 0, 0, 0 ,0 ,0 ,0])\n",
    "        elif num == 1:\n",
    "            labels_encoded.append([0, 1, 0, 0, 0, 0, 0 ,0 ,0 ,0])\n",
    "        elif num == 2:\n",
    "            labels_encoded.append([0, 0, 1, 0, 0, 0, 0 ,0 ,0 ,0])\n",
    "        elif num == 3:\n",
    "            labels_encoded.append([0, 0, 0, 1, 0, 0, 0 ,0 ,0 ,0])\n",
    "        elif num == 4:\n",
    "            labels_encoded.append([0, 0, 0, 0, 1, 0, 0 ,0 ,0 ,0])\n",
    "        elif num == 5:\n",
    "            labels_encoded.append([0, 0, 0, 0, 0, 1, 0 ,0 ,0 ,0])\n",
    "        elif num == 6:\n",
    "            labels_encoded.append([0, 0, 0, 0, 0, 0, 1, 0 ,0 ,0])\n",
    "        elif num == 7:\n",
    "            labels_encoded.append([0, 0, 0, 0, 0, 0, 0, 1 ,0 ,0])\n",
    "        elif num == 8:\n",
    "            labels_encoded.append([0, 0, 0, 0, 0, 0, 0, 0 ,1 ,0])\n",
    "        elif num == 9:\n",
    "            labels_encoded.append([0, 0, 0, 0, 0, 0, 0, 0 ,0 ,1])\n",
    "    return np.array(labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 10)\n"
     ]
    }
   ],
   "source": [
    "#Encoding labels\n",
    "train_y_encoded = encode_labels(train_y)\n",
    "print(train_y_encoded.shape) #Error Checking: Should be 42000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#Reshape our input data\n",
    "X = train_x.values\n",
    "X = X.reshape(-1,28,28,1)\n",
    "print(X.shape) #Should be [42000, 28, 28, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training:\n",
    "Now that our data is preprocessed, we will feed it into our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout\n",
    "\n",
    "#Convolutional Neural Network:\n",
    "model = Sequential()\n",
    "model.add(Conv2D(128, (3,3),input_shape=(28,28,1), activation='relu'))\n",
    "model.add(Conv2D(64, (3,3),activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(32, (3,3),activation='relu'))\n",
    "model.add(Conv2D(16, (3,3),activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/5\n",
      "33600/33600 [==============================] - 313s 9ms/step - loss: 0.7984 - acc: 0.8370 - val_loss: 0.1209 - val_acc: 0.9612\n",
      "Epoch 2/5\n",
      "33600/33600 [==============================] - 294s 9ms/step - loss: 0.1189 - acc: 0.9632 - val_loss: 0.0833 - val_acc: 0.9735\n",
      "Epoch 3/5\n",
      "33600/33600 [==============================] - 281s 8ms/step - loss: 0.0835 - acc: 0.9738 - val_loss: 0.0552 - val_acc: 0.9820\n",
      "Epoch 4/5\n",
      "33600/33600 [==============================] - 332s 10ms/step - loss: 0.0662 - acc: 0.9801 - val_loss: 0.0504 - val_acc: 0.9839\n",
      "Epoch 5/5\n",
      "33600/33600 [==============================] - 327s 10ms/step - loss: 0.0555 - acc: 0.9822 - val_loss: 0.0483 - val_acc: 0.9848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12359c9b0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, train_y_encoded,\n",
    "          batch_size=128,\n",
    "          epochs=5,\n",
    "          validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the model to make predictions on the test data and then submit it into the kaggle competition.\n",
    "test_x = test.values.reshape(-1,28,28,1)\n",
    "\n",
    "test_y = model.predict_classes(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a dataframe for submission to kaggle\n",
    "submissions=pd.DataFrame({\"ImageId\": list(range(1,len(test_y)+1)),\n",
    "                         \"Label\": test_y})\n",
    "submissions.to_csv(\"DR.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this model I managed to score **0.98514 accuracy** on the kaggle competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Performance: Normalizing the Data\n",
    "\n",
    "Another data preprocessing step that we can do is called normalization. To normalize the data means to center the data around zero mean and unit variance. Usually, this will improve the accuracy of our models, since variation in image's pixel intensities are reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reload the data\n",
    "train = pd.read_csv(\"Data/train.csv\")\n",
    "\n",
    "#Seperate Input X and Labels Y\n",
    "X_train = train.drop(['label'],axis=1)\n",
    "y_train = train.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode the training labels\n",
    "y_train = encode_labels(y_train)\n",
    "\n",
    "#Reshape the Data into a 28x28x1 matrix\n",
    "X = train_x.values\n",
    "X = X.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the input data\n",
    "mean = X.mean().astype(np.float32)\n",
    "std = X.std().astype(np.float32)\n",
    "\n",
    "X_normalized = (X-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/5\n",
      "33600/33600 [==============================] - 286s 9ms/step - loss: 0.1453 - acc: 0.9657 - val_loss: 0.0500 - val_acc: 0.9838\n",
      "Epoch 2/5\n",
      "33600/33600 [==============================] - 343s 10ms/step - loss: 0.0446 - acc: 0.9859 - val_loss: 0.0453 - val_acc: 0.9855\n",
      "Epoch 3/5\n",
      "33600/33600 [==============================] - 320s 10ms/step - loss: 0.0354 - acc: 0.9887 - val_loss: 0.0389 - val_acc: 0.9875\n",
      "Epoch 4/5\n",
      "33600/33600 [==============================] - 301s 9ms/step - loss: 0.0303 - acc: 0.9899 - val_loss: 0.0381 - val_acc: 0.9880\n",
      "Epoch 5/5\n",
      "33600/33600 [==============================] - 229s 7ms/step - loss: 0.0271 - acc: 0.9912 - val_loss: 0.0416 - val_acc: 0.9877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12359cfd0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit model using normalized data\n",
    "model.fit(X_normalized, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=5,\n",
    "          validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that normalizing our data helps our model both in speed and accuracy. We can see that after the 2nd epoch, our new model was already achieving the accuracy of our previous model after 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_test = test_x.mean().astype(np.float32)\n",
    "std_test = test_x.std().astype(np.float32)\n",
    "\n",
    "test_x_normalized = (test_x - mean_test)/std_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(test_x_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a dataframe for submission to kaggle\n",
    "submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n",
    "                         \"Label\": predictions})\n",
    "submissions.to_csv(\"DR_Normalized.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this submission, we were able to achieve an accuracy of **0.98571**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
